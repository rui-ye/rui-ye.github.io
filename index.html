<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Rui Ye</title>
  
  <meta name="author" content="Rui Ye">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  <style>
    .scrollable-list {
        max-height: 215px; /* Ë∞ÉÊï¥Ëøô‰∏™È´òÂ∫¶‰ª•ÈÄÇÂ∫î7Ë°åÊñáÊú¨ÁöÑÊòæÁ§∫ */
        overflow-y: auto; /* ÊòæÁ§∫ÂûÇÁõ¥ÊªöÂä®Êù° */
        width: 100%; /* ÊàñÊ†πÊçÆÈúÄË¶ÅË∞ÉÊï¥ÂÆΩÂ∫¶ */
        border: none;
        margin: 0 auto;
    }
    table {
        width: 100%;
        border-spacing: 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
    }
    ul {
        list-style-type: disc; /* ÂèñÊ∂àÈªòËÆ§ÁöÑÂàóË°®Ê†áËÆ∞ */
        padding: 20; /* ÂèñÊ∂àÈªòËÆ§ÁöÑÂÜÖËæπË∑ù */
    }
    ul li {
        padding: 2px; /* Ê∑ªÂä†ÊØè‰∏ÄÈ°πÁöÑÂÜÖËæπË∑ù */
    }

    .tag {
      display: inline-block;
      background-color: #0073e6;
      color: rgb(33, 32, 32);
      padding: 3px 7px;
      border-radius: 15px;
      font-size: 0.8em;
      margin-right: 5px;
    }

    .tag-llm {
      background-color: #ffc8dd;
    }

    .tag-trust {
      background-color: #cdb4db;
    }

    .tag-co {
      background-color: #bde0fe;
    }

    .tag-fl {
      background-color: #a2d2ff;
    }
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rui Ye / Âè∂Èîê</name>
              </p>
              <p>I am a third-year PhD candidate at <a href="https://en.sjtu.edu.cn">Shanghai Jiao Tong University (SJTU)</a> in Shanghai, China. Before that, I received my Bachelor degree from <a href="https://en.sjtu.edu.cn">SJTU</a>, ranked the <u>first out of 150</u>.
              </p>
              <p>
                I am currently advised by <a href="https://siheng-chen.github.io">Prof. Siheng Chen</a>, in the <a href="https://mediabrain.sjtu.edu.cn">MediaBrain Lab</a>. My research interests lie in <u>Collaborative AI and Trustworthy AI</u>, with a particular focus on LLM-based multi-agent systems, trustworthy large language models (LLMs), and federated learning. I have previously interned at Microsoft Research Asia (MSRA) and Shanghai AI Laboratory.
              </p>
              <p>
                I am actively seeking collaborations and opportunities as a <strong>research intern or visiting student</strong>, please feel free to contact me!!!
              </p>
              <p style="text-align:center">
                <a href="mailto:yr991129@sjtu.edu.cn">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=Q4-VTxcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/rui-ye/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/rui-ye-a66b2420a/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/ruiye1129">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%; width:40%; max-width:40%">
              <a href="images/ruiye.png">
                <img style="width: 80%; max-width: 100%; height: 250px; object-fit: cover;" alt="profile photo" src="images/ruiye.png" class="hoverZoomLink">
              </a>
            </td>            
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>üî• News</heading>
          </td>
        </tr>
        </tbody></table>

        <table>
          <tbody>
              <tr>
                  <td>
                      <div class="scrollable-list">
                          <ul>
                              <li>[2025.01] One paper about safety attack in FedLLM is accepted by <strong>ICLR 2025</strong>! See you in Singapore!</li>
                              <li>[2024.12] Have been reviewed by LLMs? Check our <a href="https://arxiv.org/abs/2412.01708">recent work</a> on revealing their drawbacks and our advocacy!</li>
                              <li>[2024.09] I was awarded the <strong>National Scholarship</strong> 2024, thanks to the guidance of Prof. Chen.</li>
                              <li>[2024.09] One paper (<a href="https://arxiv.org/pdf/2406.04845.pdf">FedLLM-Bench</a>) is accepted by <strong>NeurIPS 2024</strong>!</li>
                              <li>[2024.08] One co-first authored paper (FedRSU) is accepted by <strong>T-ITS</strong>!</li>
                              <li>[2024.06] We release the first realistic benchmark for FedLLM: <a href="https://arxiv.org/pdf/2406.04845.pdf">FedLLM-Bench</a>!</li>
                              <li>[2024.05] One paper (<a href="https://arxiv.org/pdf/2402.06954.pdf">OpenFedLLM</a>) is accepted by <strong>KDD 2024</strong>!</li>
                              <li>[2024.05] One co-first authored paper (Reverse Alignment) is accepted by <strong>Findings of ACL 2024</strong>!</li>
                              <li>[2024.05] One co-first authored paper (MATRIX) is accepted by <strong>ICML 2024 (Spotlight)</strong>! See you in Austria!</li>
                              <li>[2024.02] We release a comprehensive [FL x LLMs] framework <a href="https://arxiv.org/pdf/2402.06954.pdf">OpenFedLLM</a>!!!</li>
                              <li>[2024.01] One paper (FedCOG) is accepted by <strong>ICLR 2024</strong>! See you in Vienna!</li>
                              <li>[2023.08] One paper (FedFM) is accepted by <strong>IEEE Transactions on Signal Processing (T-SP)</strong>!</li>
                              <li>[2023.07] Start second internship at Microsoft Research Asia <strong>(MSRA)</strong>, Beijing (on-site).</li>
                              <li>[2023.04] Two papers (FedDisco & pFedGraph) are accepted by <strong>ICML 2023</strong>! See you in Hawaii!</li>
                              <li>[2022.11] Start internship at Microsoft Research Asia <strong>(MSRA)</strong>, Beijing (remote).</li>
                          </ul>
                      </div>
                  </td>
              </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>üìë Publications</heading>
              <p>
                <sup>*</sup> denotes equal contribution, <sup>‚Ä†</sup> denotes corresponding author, see full list in <a href="https://scholar.google.com/citations?user=Q4-VTxcAAAAJ&hl=zh-CN">Google Scholar</a>, some are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
    
    <style> /* Year title format */
      .year-title {
        font-size: 18px;
        font-weight: bold;
        margin-left: 20px;
      }
    </style>

    <div class="year-title">2024</div>

    <table style="width:100%;border:0px;border-spacing:0 5px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/masgpt_overview.png" alt="masgpt" width="160">
          <p><img src="images/masgpt_reasoning.png" alt="masgpt" width="160"></p>
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems</papertitle></div>
          <div class="tags" data-tags="llm,co"></div>
          <strong>Rui Ye</strong>, Shuo Tang, Rui Ge, Yaxin Du, Zhenfei Yin, Siheng Chen<sup>‚Ä†</sup>, Jing Shao<sup>‚Ä†</sup>
          <br>
          <em>Preprint</em>, 2025
          <br>
          <a href="https://arxiv.org/pdf/2503.03686">arXiv</a> / <a href="data/masgpt.bib">BibTeX</a>
          <br>
          <p> This paper proposes to formulate the process of building LLM-based multi-agent systems (MAS) as a generative task, making it as simple as querying ChatGPT. We design a dataset construction pipeline and train MAS-GPT, a 32B LLM capable of generating an executable MAS give any specific query. Results demonstrate MAS-GPT‚Äôs simplicity, cost-efficiency, and generality.</p>
        </td>
      </tr>

      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/badllmreviewer.png" alt="badllmreviewer" width="160">
          <p><img src="images/badllmreviewer_case.png" alt="badllmreviewer" width="160"></p>
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review</papertitle></div>
          <div class="tags" data-tags="llm,trust"></div>
          <strong>Rui Ye<sup>*</sup></strong>, <span style="font-size: 11px;">Xianghe Pang<sup>*</sup>, Jingyi Chai, Jiaao Chen, Zhenfei Yin, Zhen Xiang, Xiaowen Dong, Jing Shao, Siheng Chen<sup>‚Ä†</sup></span>
          <br>
          <em>Preprint</em>, 2024
          <br>
          <a href="https://arxiv.org/abs/2412.01708">arXiv</a> / <a href="data/badllmreviewer.bib">BibTeX</a> / <a href="https://rui-ye.github.io/BadLLMReviewer/">Project Page</a>
          <br>
          <p> Given that LLMs are being integrated into peer review, in this study, we comprehensively reveal the vulnerabilities of LLM-generated reviews by focusing on (explicit and implicit) manipulation and inherent flaws (hallucination and bias). Our findings underscore that we are not yet ready for widespread adoption, emphasizing the need for punitive measures, detection techniques, and robust safeguards.</p>
        </td>
      </tr>
      
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/fedllmattack_overview.png" alt="fedllmattack" width="160">
          <p><img src="images/fedllmattack_results.png" alt="fedllmattack" width="160"></p>
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models</papertitle></div>
          <div class="tags" data-tags="llm,fl,trust,co"></div>
          <strong>Rui Ye<sup>*</sup></strong>, Jingyi Chai<sup>*</sup>, Xiangrui Liu, Yaodong Yang, Yanfeng Wang, Siheng Chen<sup>‚Ä†</sup>
          <br>
          <em>International Conference on Learning Representations (ICLR)</em>, 2025
          <br>
          <a href="https://arxiv.org/abs/2406.10630">arXiv</a> / <a href="data/fedllmattack.bib">BibTeX</a>
          <br>
          <p> This paper for the first time reveals the vulnerability of safety alignment during federated instruction tuning by proposing a simple safety attack method. While many existing FL defense methods fail to defend against such attack, we propose a post-hoc defense method that automatically and effectively enhances the safety alignment of LLMs.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/fedllmbench_table.png" alt="fedllmbench" width="160">
          <p><img src="images/fedllmbench_quality.png" alt="fedllmbench" width="160"></p>
          <p><img src="images/fedllmbench_emb.png" alt="fedllmbench" width="160"></p>
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models</papertitle></div>
          <div class="tags" data-tags="llm,fl,trust,co"></div>
          <strong>Rui Ye<sup>*</sup></strong>, Rui Ge<sup>*</sup>, Xinyu Zhu, Jingyi Chai, Yaxin Du, Yang Liu, Yanfeng Wang, Siheng Chen<sup>‚Ä†</sup>
          <br>
          <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2024
          <br>
          <a href="https://arxiv.org/abs/2406.04845">arXiv</a> / <a href="data/fedllmbench.bib">BibTeX</a> / <a href="https://github.com/rui-ye/FedLLM-Bench">Code</a> <img src="https://img.shields.io/github/stars/rui-ye/FedLLM-Bench?style=social"/>
          <br>
          <p> This paper proposes the first realistic benchmark for federated learning of large language models, termed FedLLM-Bench. It encompasses 3 datasets for instruction tuning task and 1 dataset for preference alignment task, which exhibit diversities in language, quality, quantity, instruction, length, embedding, and preference.</p>
        </td>
      </tr>
      
      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/openfedllm.png" alt="openfedllm" width="160">
          <p><img src="images/openfedllm_comp.png" alt="openfedllm" width="160"></p>
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning</papertitle></div>
          <div class="tags" data-tags="llm,fl,trust,co"></div>
          <strong>Rui Ye</strong>, <span style="font-size: 12px;">Wenhao Wang, Jingyi Chai, Dihan Li, Zexi Li, Yinda Xu, Yaxin Du, Yanfeng Wang, Siheng Chen<sup>‚Ä†</sup></span>
          <br>
          <em>Conference on Knowledge Discovery and Data Mining (KDD)</em>, 2024
          <br>
          <em>ICLR AGI Workshop and DPFM Workshop</em>, 2024
          <br>
          <a href="https://arxiv.org/abs/2402.06954">arXiv</a> / <a href="https://dl.acm.org/doi/abs/10.1145/3637528.3671582">ACM</a> / <a href="data/openfedllm.bib">BibTeX</a> / <a href="https://github.com/rui-ye/OpenFedLLM">Code</a> <img src="https://img.shields.io/github/stars/rui-ye/OpenFedLLM?style=social"/>
          <br>
          <p> This paper proposes OpenFedLLM for training large language models on decentralized private data via federated learning, which covers instruction tuning, value alignment, 7 FL algorithms, 8 training datasets, and 30+ evaluation metrics. Based on OpenFedLLM, we conduct a comprehensive empirical study, provide insights, and point out future directions.</p>
        </td>
      </tr>

      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/matrix.png" alt="matrix" width="160">
          <p><img src="images/matrix_eval.png" alt="matrix" width="160"></p>
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation</papertitle></div>
          <div class="tags" data-tags="llm,trust,co"></div>
          Xianghe Pang<sup>*</sup>, Shuo Tang<sup>*</sup>, <strong>Rui Ye<sup>*</sup></strong>, Yuxin Xiong, Bolun Zhang, Yanfeng Wang, Siheng Chen<sup>‚Ä†</sup>
          <br>
          <em>International Conference on Machine Learning (ICML)</em>, <strong>Spotlight</strong>, 2024
          <br>
          <em>ICLR AGI Workshop</em>, <strong>Oral</strong>, 2024
          <br>
          <a href="https://arxiv.org/abs/2402.05699">arXiv</a> / <a href="https://openreview.net/forum?id=l7shXGuGBT">OpenReview</a> / <a href="data/matrix.bib">BibTeX</a> / <a href="https://shuotang123.github.io/MATRIX/">Project</a> / <a href="https://github.com/ShuoTang123/MATRIX">Code</a> <img src="https://img.shields.io/github/stars/ShuoTang123/MATRIX?style=social"/>
          <br>
          <p> This paper proposes to self-align large language models via social scene simulation, which is powered by our proposed simulator called MATRIX. Human evaluations show that our aligned 13/30B LLMs can outperform GPT-4 on value alignment.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/ipfl.png" alt="ipfl" width="160">
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>Incentivizing Inclusive Data Contributions in Personalized Federated Learning</papertitle></div>
          <div class="tags" data-tags="llm,fl,co,trust"></div>
          Enpei Zhang<sup>*</sup>, Jingyi Chai<sup>*</sup>, <strong>Rui Ye<sup>*</sup></strong>, Yanfeng Wang, Siheng Chen<sup>‚Ä†</sup>
          <br>
          <em>ICLR AGI Workshop and DPFM Workshop</em>, 2024
          <br>
          <a href="https://openreview.net/forum?id=o44e77vYhE">OpenReview</a> / <a href="data/ipfl.bib">BibTeX</a>
          <br>
          <p> This paper proposes inclusive and incentivized personalized federated learning (iPFL), which incentivizes data holders with diverse purposes to collaboratively train personalized models without revealing raw data. </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/reverse_alignment.png" alt="reverse_alignment" width="160">
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>On the Vulnerability of Safety Alignment in Open-Access LLMs</papertitle></div>
          <div class="tags" data-tags="llm,trust"></div>
          <span style="font-size: 11px;">Jingwei Yi<sup>*</sup></span>, <strong>Rui Ye<sup>*</sup></strong>, <span style="font-size: 11px;">Qisi Chen, Bin Zhu, Siheng Chen<sup>‚Ä†</sup>, Defu Lian, Guangzhong Sun, Xing Xie, Fangzhao Wu<sup>‚Ä†</sup></span>
          <br>
          <em>Findings of the Association for Computational Linguistics (ACL)</em>, 2024
          <br>
          <a href="https://aclanthology.org/2024.findings-acl.549.pdf">Paper</a> / <a href="data/reverse.bib">BibTeX</a>
          <br>
          <p> This paper unreveals the vulnerability of value alignment in aligned open-source LLMs by proposing a series of efficient attack methods (i.e., reverse alignment). Experiments show that simple fine-tuning can significantly compromise the alignment of the LLMs.</p>
        </td>
      </tr>
    </tbody></table>

    <div class="year-title">2023</div>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/fedgc.png" alt="fedgc" width="160">
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>Federated Learning Empowered by Generative Content</papertitle></div>
          <div class="tags" data-tags="fl,trust,co,llm"></div>
          <strong>Rui Ye</strong>, Xinyu Zhu, Jingyi Chai, Siheng Chen<sup>‚Ä†</sup>, Yanfeng Wang
          <br>
          <em>NeurIPS FL@FM Workshop</em>, 2024
          <br>
          <a href="https://arxiv.org/abs/2312.05807">arXiv</a> / <a href="data/fedgc.bib">BibTeX</a>
          <br>
          <p> This paper for the <strong>first time</strong> explores how advanced generative models can benefit FL on heterogeneous private data. We show that generative content can not only mitigate data heterogeneity, but also enhance privacy preservation for FL.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/fedcog.png" alt="fedcog" width="160">
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>Fake It Till Make It: Federated Learning with Consensus-Oriented Generation</papertitle></div>
          <div class="tags" data-tags="fl,trust,co"></div>
          <strong>Rui Ye</strong>, Yaxin Du, Zhenyang Ni, Siheng Chen<sup>‚Ä†</sup>, Yanfeng Wang
          <br>
          <em>International Conference on Learning Representations (ICLR)</em>, 2024
          <br>
          <a href="https://openreview.net/pdf?id=NY3wMJuaLf">Paper</a> / <a href="data/fedcog.bib">BibTeX</a> / <a href="https://github.com/rui-ye/FedCOG">Code</a>
          <br>
          <p> This paper proposes to more fundamentally handle data heterogeneity from the perspective of data, which is achieved by extracting consensus data from the global model to complement clients' heterogeneous data.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/feddisco.png" alt="feddisco" width="160">
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>FedDisco: Federated Learning with Discrepancy-aware Collaboration</papertitle></div>
          <div class="tags" data-tags="fl,trust,co"></div>
          <strong>Rui Ye</strong>, Mingkai Xu, Jianyu Wang, Chenxin Xu, Siheng Chen<sup>‚Ä†</sup>, Yanfeng Wang
          <br>
          <em>International Conference on Machine Learning (ICML)</em>, 2023
          <br>
          <a href="https://arxiv.org/abs/2305.19229">arXiv</a> / <a href="data/feddisco.bib">BibTeX</a> / <a href="https://proceedings.mlr.press/v202/ye23f.html">PMLR</a> / <a href="https://github.com/MediaBrain-SJTU/FedDisco">Code</a> <img src="https://img.shields.io/github/stars/MediaBrain-SJTU/FedDisco?style=social"/>
          <br>
          <p> Based on our empirical and theoretical observations, we propose to aggregate models based on both dataset size and a defined discrepancy value. </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/pfedgraph.png" alt="pfedgraph" width="160">
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>Personalized Federated Learning with Inferred Collaboration Graphs</papertitle></div>
          <div class="tags" data-tags="fl,trust,co"></div>
          <strong>Rui Ye<sup>*</sup></strong>, Zhenyang Ni<sup>*</sup>, Fangzhao Wu, Siheng Chen<sup>‚Ä†</sup>, Yanfeng Wang
          <br>
          <em>International Conference on Machine Learning (ICML)</em>, 2023
          <br>
          <a href="https://proceedings.mlr.press/v202/ye23b.html">PMLR</a> / <a href="data/pfedgraph.bib">BibTeX</a> / <a href="https://github.com/MediaBrain-SJTU/pFedGraph">Code</a> <img src="https://img.shields.io/github/stars/MediaBrain-SJTU/pFedGraph?style=social"/>
          <br>
          <p> We propose a pFedGraph algorithm to promote more collaboration between clients with more similar data distributions. </p>
        </td>
      </tr>
      
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/fedfm.png" alt="fedfm" width="160">
        </td>
        <!-- <td width="75%" valign="center"> -->
        <td style="padding:20px;width:75%;vertical-align:middle">
          <div style="color: cornflowerblue;"><papertitle>FedFM: Anchor-based Feature Matching for Data Heterogeneity in Federated Learning</papertitle></div>
          <div class="tags" data-tags="fl,trust,co"></div>
          <strong>Rui Ye</strong>, Zhenyang Ni, Chenxin Xu, Jianyu Wang, Siheng Chen<sup>‚Ä†</sup>, Yanfeng Wang
          <br>
          <em>IEEE Transactions on Signal Processing (TSP)</em>, 2023
          <br>
          <a href="https://arxiv.org/abs/2210.07615">Paper</a> / <a href="https://ieeexplore.ieee.org/abstract/document/10286439">IEEE</a> / <a href="data/fedfm.bib">BibTeX</a> / <a href="https://github.com/rui-ye/FedFM">Code (PyTorch, PaddlePaddle, MindSpore)</a>
          <br>
          <p> We propose to align category-wise feature spaces of clients in FL, which achieves pleasant performance with theoretical convergence guarantee. </p>
        </td>
      </tr>
    
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>üéì Educations</heading>
      </td>
    </tr>
  </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle;">
        <img src="images/sjtu.png" alt="sjtu" width="100">
      </td>
      <!-- <td width="75%" valign="center"> -->
      <td style="padding:20px;width:75%;vertical-align:middle">
        Degree: Bachelor
        <br>
        Period: 2018.09 - 2022.06
        <br>
        Major:  Information Engineering (AI Class)
        <br>
        <strong>GPA:    3.94/4.3 (ranked 1st out of 150)</strong>
      </td>
    </tr>

  </tbody></table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
        <td>
          <heading>ü•á Honors & Awards</heading>
        </td>
      </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td>
          <ul>
            <li><strong>National Scholarship</strong> for PhD Students, 2024</li>
            <li><strong>National Scholarship</strong> for Undergraduates, 2020 (2 out of 150)</li>
            <li><strong>Shanghai Outstanding Graduates</strong>, 2022</li>
            <li>Samsung Scholarship, 2023 (only one awardee)</li>
            <li>Mathematical Contest in Modeling, Finalist, 2021 (<1%)</li>
            <li>Shanghai Jiao Tong University Wenjun Wu AI Class, 2022 (16 are selected)</li>
            <li>Shanghai Jiao Tong University Xu Zhang Academician Scholarship, 2022 (3 out of 150)</li>
            <li>Shanghai Jiao Tong University Ceyear Scholarship, 2021</li>
            <li>Shanghai Jiao Tong University Fujian Alumni Association Scholarship, 2019 (the youngest awardee)</li>
            <li>Shanghai Jiao Tong University Class B Scholarship, 2019&2020&2021</li>
          </ul>
        </td>
      </tr>
    </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>üëÄ Misc</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <strong>Review</strong>:
              <ul>
                <li> 2025: ICLR, ICML, CPVR, AAAI</li>
                <li> 2024: ICLR, ICML, NeurIPS Main, NeurIPS Data, ICASSP</li>
                <li> 2023: NeurIPS Main</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <strong>Life</strong>:I love playing basketball / listening rap music / travelling.
            </td>
          </tr>
        </tbody></table>


        <table width="50%" align="center" border="0" cellpadding="20"><tbody>
					
          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
					
          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr> -->
				
				<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=7PmJikxJk324BBRWUrbE2SWNBd9X6PBJ1XTz2PMpA7k&cl=ffffff&w=a"></script>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Derived from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

  <!-- Definations for tags -->
  <script>
    // È¢ÑÂÆö‰πâÊ†áÁ≠æÁöÑÂêçÁß∞ÂíåÁÆÄÁß∞
    const tagsMap = {
      'llm': { name: 'LLMs', class: 'tag-llm' },
      'trust': { name: 'Trustworhty AI', class: 'tag-trust' },
      'co': { name: 'Collaborative AI', class: 'tag-co' },
      'fl': { name: 'Federated Learning', class: 'tag-fl' },
    };
  
    // Ê∏≤ÊüìÊ†áÁ≠æÂπ∂‰∏∫‰∏çÂêåÊ†áÁ≠æÂàÜÈÖç‰∏çÂêåÁöÑCSSÁ±ª
    document.querySelectorAll('.tags').forEach(tagDiv => {
      const tagAbbreviations = tagDiv.getAttribute('data-tags').split(',');
      tagAbbreviations.forEach(abbreviation => {
        if (tagsMap[abbreviation]) {
          const tagElement = document.createElement('span');
          tagElement.classList.add('tag', tagsMap[abbreviation].class);
          tagElement.textContent = tagsMap[abbreviation].name;
          tagDiv.appendChild(tagElement);
        }
      });
    });
  </script>
</body>

</html>
